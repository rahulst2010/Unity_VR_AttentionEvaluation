# Unity_VR_AttentionEvaluation

# AR for Attention Management

In the modern age, there are huge volumes of data that people come across in their everyday lives. Evolution of technology and smart devices have brought about this change effectively over the past few years, giving access to data from a variety of sources over the internet among other media. Although it gives us the opportunity for self-education, better decision making, etc. with the accessibility of resources, it creates cognitive overload with the burden of abundance in information. It takes a special skill to navigate through this expanse with challenges of expectations and inclinations, and to finally arrive at the optimal solution that one hopes for. Several applications for mobile phones, personal computers, websites and other devices provide assistance and specificity in functionalities we can enjoy but still lacks in perfection to deliver personalization and synchronous integration of essential features. Simple day to day activities from the time of waking up, right until going to bed, we make meticulous decisions and spare attention to planned as well as impulsive actions. 

# DESCRIPTION: 
Hence, the proposed system is intended to resolve this underlying complication with the application of Augmented Reality.
It exhibits competence in the field with the ability to gain greater attention span using graphical visualization. Studies have proven that 90% of information transmitted to the brain is visual, and that they are processed numerously faster in the brain than text and other forms of data. Thus, the primary goals that are focused here are the following,
•	Reduction in cognitive workload: Visualization using Augmented Reality with headsets to get user attention for critical activities. 
•	Analysis of real time visuals to learn progress: Computer Vision with device camera.
The AR device has native programming that pairs with this data for creation of personal feedback loops and suggestions. Once the device is activated, it allows users to keep track their activities by forming a schedule to follow, graphical alerts when time to execute an action and visual cues to direct spatial attention to tasks by augmenting visuals on real world environment. Computer Vision technology elevates the performance by object recognition and smart identification features of images captured out of live camera present in the device. This data is fed into an intelligence component that carries out analysis and processes online information to decide upon the respective action and if it needs any suggestions or updates. As the subsequent action is identified, it is then relayed back to the AR device for rendering to make users attentive and the cycle follows on. 
SYSTEM COMPONENTS: The system comprises of an AR headset and a UI application that are integrated to a live processing unit located remotely in a cloud infrastructure with sufficient hardware and storage capabilities. It is here where the machine intelligence lie which makes decisions and determines suitable actions in order to present that to users for gaining attention. As users begin interacting with the tool, it gets smarter over the course of time and accommodates their preferences, to their own style of handling tasks and making decisions. The Database stores user entered content, profile updates based on acquired knowledge and schedules/actions.
USE CASES:
•	Users wearing headsets will be directed towards the kitchen fridge and dynamically highlight the product (eg., Milk) showing that the quantity is less and suggested buying a new can.
•	While a user leaves home or work, computer vision can identify an object such as an ID card or wallet and keeps track of its presence and geo location and reminds the user if it has been forgotten.
•	Activity planning allows users to rely on the AR for visual cues to provide suggestive actions and events planned in order to fulfill an action.
•	Based on current locale information, the ML component dynamically decides on wardrobe suggestions considering weather and user inventory for the best option that is relayed to users graphically over AR device when users step out. 
•	Users use haptic signals to interact with AR to cross off actions from the checklist.

![image](https://github.com/user-attachments/assets/473c9577-3795-4de3-b6de-c256196ab0ea)



![image](https://github.com/user-attachments/assets/f6be0b79-a9bd-466b-9dd6-886e3538dde2)

![image](https://github.com/user-attachments/assets/a848c5ba-3286-42f7-81d0-2437064901eb)

![image](https://github.com/user-attachments/assets/2814a545-e0d0-40f7-8c54-89beba5671ac)
